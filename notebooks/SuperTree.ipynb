{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading and Visualizing Tree Point Clouds\n",
    "\n",
    "### Create Label-Mapping and Label Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "FOR_Instance_num_classes = 3\n",
    "\n",
    "ID2TRAINID = np.asarray([\n",
    "    FOR_Instance_num_classes,   # 0 Unclassified        ->  3 Ignored\n",
    "    1,                          # 1 Low vegetation      ->  1 Low vegetation\n",
    "    0,                          # 2 Terrain             ->  0 Ground\n",
    "    FOR_Instance_num_classes,   # 3 Out-points          ->  3 Ignored\n",
    "    2,                          # 4 Stem                ->  2 Tree\n",
    "    2,                          # 5 Live branches       ->  2 Tree\n",
    "    2,                          # 6 Woody branches      ->  2 Tree\n",
    "])\n",
    "\n",
    "FOR_Instance_CLASS_NAMES = [\n",
    "    'Ground',\n",
    "    'Low vegetation',\n",
    "    'Tree',\n",
    "    'Ignored']\n",
    "\n",
    "# Class color palette\n",
    "FOR_Instance_CLASS_COLORS = np.asarray([\n",
    "    [243, 214, 171],\n",
    "    [204, 213, 174],\n",
    "    [ 70, 115,  66],\n",
    "    [  0,   0,   0]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a Data reader\n",
    "\n",
    "Data object is a simple class based on PyG's Data object for holding point clouds (graphs). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .copy() Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "file_path = os.path.dirname(os.path.abspath(''))  # for .ipynb notebook\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import laspy\n",
    "from src.data import Data\n",
    "from src.utils.color import to_float_rgb\n",
    "\n",
    "data = Data()\n",
    "las_filepath = \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/NIBIO/plot_1_annotated.las\"\n",
    "las_vancouver_filepath = \"/home/valerio/git/superpoint_transformer_vschelbi/data/491000_5454000/491000_5454000.las\"\n",
    "\n",
    "las = laspy.read(las_filepath)\n",
    "las_vancouver = laspy.read(las_vancouver_filepath)\n",
    "\n",
    "print(las.header)\n",
    "dimensions = las.point_format.dimension_names\n",
    "print(\"Available dimensions: \")\n",
    "for dim in dimensions:\n",
    "    print(dim)\n",
    "\n",
    "print(las_vancouver.header)\n",
    "dimensions = las_vancouver.point_format.dimension_names\n",
    "print(\"Available dimensions: \")\n",
    "for dim in dimensions:\n",
    "    print(dim)\n",
    "\n",
    "\n",
    "x_pos = las[\"X\"].copy()\n",
    "y_pos = las[\"Y\"].copy()\n",
    "z_pos = las[\"Z\"].copy()\n",
    "x_tensor = torch.tensor(x_pos)\n",
    "y_tensor = torch.tensor(y_pos)\n",
    "z_tensor = torch.tensor(z_pos)\n",
    "torch_pos = torch.stack([x_tensor, y_tensor, z_tensor], dim=-1)\n",
    "\n",
    "\n",
    "xyz = True\n",
    "# populate the Data object with point coordinates\n",
    "if xyz:\n",
    "    # Apply the scale provided by the LAS header\n",
    "    pos = torch.stack([\n",
    "        torch.tensor(las[axis].copy())\n",
    "        for axis in [\"X\", \"Y\", \"Z\"]], dim=-1)\n",
    "    pos *= las.header.scale\n",
    "    pos_offset = pos[0]\n",
    "    data.pos = (pos - pos_offset).float()\n",
    "    data.pos_offset = pos_offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project's files to the python path\n",
    "# file_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # for .py script\n",
    "file_path = os.path.dirname(os.path.abspath(''))  # for .ipynb notebook\n",
    "sys.path.append(file_path)\n",
    "\n",
    "import laspy\n",
    "import torch\n",
    "from src.data import Data, InstanceData\n",
    "from src.utils.color import to_float_rgb\n",
    "from torch_geometric.nn.pool.consecutive import consecutive_cluster\n",
    "\n",
    "\n",
    "def read_FORinstance_plot(\n",
    "    filepath,\n",
    "    xyz=True,\n",
    "    rgb=True,\n",
    "    intensity=True,\n",
    "    semantic=True,\n",
    "    instance=False,\n",
    "    remap=True,\n",
    "    max_intensity=600):\n",
    "    \"\"\"Read a FORinstance file saved as LAS.\n",
    "\n",
    "    :param filepath: str\n",
    "        Absolute path to the LAS file\n",
    "    :param xyz: bool\n",
    "        Whether XYZ coordinates should be saved in the output Data.pos\n",
    "    :param rgb: bool\n",
    "        Whether RGB colors should be saved in the output Data.rgb\n",
    "    :param intensity: bool\n",
    "        Whether intensity should be saved in the output Data.rgb\n",
    "    :param semantic: bool\n",
    "        Whether semantic labels should be saved in the output Data.y\n",
    "    :param instance: bool\n",
    "        Whether instance labels should be saved in the output Data.obj\n",
    "    :param remap: bool\n",
    "        Whether semantic labels should be mapped from their FORinstance ID\n",
    "        to their train ID\n",
    "    :param max_intensity: float\n",
    "        Maximum value used to clip intensity signal before normalizing \n",
    "        to [0, 1]\n",
    "    \"\"\"\n",
    "\n",
    "    # create an empty Data object\n",
    "    data = Data()\n",
    "    las = laspy.read(filepath)\n",
    "\n",
    "    # populate the Data object with point coordinates\n",
    "    if xyz:\n",
    "        # Apply the scale provided by the LAS header\n",
    "        pos = torch.stack([\n",
    "            torch.tensor(las[axis].copy())\n",
    "            for axis in [\"X\", \"Y\", \"Z\"]], dim=-1)\n",
    "        pos *= las.header.scale\n",
    "        pos_offset = pos[0]\n",
    "        data.pos = (pos - pos_offset).float()\n",
    "        data.pos_offset = pos_offset\n",
    "    \n",
    "    # Populate data with point RGB colors\n",
    "    if rgb:\n",
    "        # RGB stored in uint16 lives in [0, 65535]\n",
    "        data.rgb = to_float_rgb(torch.stack([\n",
    "            torch.FloatTensor(las[axis].astype('float32') / 65535)\n",
    "            for axis in [\"red\", \"green\", \"blue\"]], dim=-1))\n",
    "    \n",
    "    # Populate data with point LiDAR intensity\n",
    "    if intensity:\n",
    "        # Heuristic to bring the intensity distribution in [0, 1]\n",
    "        data.intensity = torch.FloatTensor(\n",
    "            las['intensity'].astype('float32')\n",
    "        ).clip(min=0, max=max_intensity) / max_intensity\n",
    "\n",
    "    # Populate data with point semantic segmentation labels\n",
    "    if semantic:\n",
    "        y = torch.LongTensor(las['classification'])\n",
    "        data.y = torch.from_numpy(ID2TRAINID)[y] if remap else y\n",
    "\n",
    "    if instance:\n",
    "        idx = torch.arange(data.num_points)\n",
    "        obj = torch.LongTensor(las['treeID'])\n",
    "        obj = consecutive_cluster(obj)[0]\n",
    "        count = torch.ones_like(obj)\n",
    "        y = torch.LongTensor(las['classification'])\n",
    "        y = torch.from_numpy(ID2TRAINID)[y] if remap else y\n",
    "        data.obj = InstanceData(idx, obj, count, y, dense=True)\n",
    "\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data and Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/SCION/plot_87_annotated.las\"\n",
    "data = read_FORinstance_plot(filepath, rgb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show(max_points=100000, keys=['intensity'], class_names=FOR_Instance_CLASS_NAMES, class_colors=FOR_Instance_CLASS_COLORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Tiling Done On This File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiling code would go here, SPT provides two tiling strategies:\n",
    "# 1. SampleXYTiling, when clouds have a simple, convex, axis-aligned horizontal layout\n",
    "# 2. SampleRecursiveMainXYAxisTiling => when couds have a complex horizontal layouts (like streets etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a pretrained model for inference\n",
    "First get the same transforms as the pretrained model used, in this case DALES (in `configs/experiment`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving Config and transforms from pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import init_config\n",
    "from src.transforms import instantiate_datamodule_transforms\n",
    "\n",
    "cfg = init_config(overrides=[f\"experiment=semantic/dales\"])\n",
    "#cfg.keys()\n",
    "\n",
    "transforms_dict = instantiate_datamodule_transforms(cfg.datamodule)\n",
    "#transforms_dict\n",
    "\n",
    "# applying the transform:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying transform\n",
    "1. apply `pre_transofrm`\n",
    "2. simulate the behavior of the dataset's input/ output behavior with\n",
    "    only `point_load_keys` and `segment_load_keys` loaded from disk\n",
    "3. apply `on_device_test_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Apply pre-transforms\n",
    "nag = transforms_dict['pre_transform'](data)\n",
    "\n",
    "# 2. Sim I/O behavior\n",
    "from src.transforms import NAGRemoveKeys\n",
    "nag = NAGRemoveKeys(level=0, keys=[k for k in nag[0].keys if k not in cfg.datamodule.point_load_keys])(nag)\n",
    "nag = NAGRemoveKeys(level='1+', keys=[k for k in nag[1].keys if k not in cfg.datamodule.segment_load_keys])(nag)\n",
    "\n",
    "nag = nag.cuda()\n",
    "nag = transforms_dict['on_device_test_transform'](nag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nag.show(class_names=FOR_Instance_CLASS_NAMES, class_colors=FOR_Instance_CLASS_COLORS, keys=nag[0].keys, centroids=True, h_edge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating the pretrained model from `configs/` and a `*.ckpt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from src.utils import init_config\n",
    "\n",
    "# Path to the downloaded checkpoint file\n",
    "ckpt_path = \"/home/valerio/git/superpoint_transformer_vschelbi/pretrained_models/spt-2_dales.ckpt\"\n",
    "cfg = init_config(overrides=[f\"experiment=semantic/dales\"])\n",
    "\n",
    "# Instantiate the model and load the weights\n",
    "model = hydra.utils.instantiate(cfg.model)\n",
    "model = model._load_from_checkpoint(ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying the SPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to inference mode and onto same device as the input data\n",
    "model = model.eval().to(nag.device)\n",
    "\n",
    "# Infernce, returns a task-specific output object carrying the model's predictions\n",
    "with torch.no_grad():\n",
    "    output = model(nag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output of the semantic segmentation is `SemanticSemgentationOuput` object. class dedictated to holding onto predictions in `output.semantic_pred` and facilitates post-processing operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.semantic_pred.shape, nag.num_points\n",
    "\n",
    "# bring predicitions to level-0 and save under the semantic_pred attribute in Data\n",
    "nag[0].semantic_pred = output.voxel_semantic_pred(super_index=nag[0].super_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the predictions\n",
    "For better visualization, use the DALES `CLASS_NAMES` and `CLASS_COLORS`, as the model was trained on those classes. The predicted labels DO NOT align with those of the FORinstance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets.dales import CLASS_NAMES as DALES_CLASS_NAMES\n",
    "from src.datasets.dales import CLASS_COLORS as DALES_CLASS_COLORS\n",
    "\n",
    "nag.show(\n",
    "    class_names=DALES_CLASS_NAMES,\n",
    "    class_colors=DALES_CLASS_COLORS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlook\n",
    "This is as far as a pretrained model can get me on the FORinstance dataset. For actually predicting the instances (of trees) and identifying the classes in the FORinstance dataset, I will ned to train a dedicated model on the FORinstance data. Besides, I will have to adjust the preprocessing steps in `pre_transform`. Different parameters may produce partitions that better respect the semantic boundaries of the FORinstance dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
