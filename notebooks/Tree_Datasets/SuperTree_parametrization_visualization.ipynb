{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the project's files to the python path\n",
    "# file_path = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # for .py script\n",
    "file_path = os.path.dirname(os.path.abspath(''))  # for .ipynb notebook\n",
    "sys.path.append(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import laspy\n",
    "import numpy as np\n",
    "\n",
    "from src.data import Data, InstanceData\n",
    "from torch_geometric.nn.pool.consecutive import consecutive_cluster\n",
    "from src.transforms import *\n",
    "\n",
    "FOR_Instance_num_classes = 3\n",
    "ID2TRAINID = np.asarray([\n",
    "    FOR_Instance_num_classes,   # 0 Unclassified        ->  3 Ignored\n",
    "    1,                          # 1 Low vegetation      ->  1 Low vegetation\n",
    "    0,                          # 2 Terrain             ->  0 Ground\n",
    "    FOR_Instance_num_classes,   # 3 Out-points          ->  3 Ignored\n",
    "    2,                          # 4 Stem                ->  2 Tree\n",
    "    2,                          # 5 Live branches       ->  2 Tree\n",
    "    2,                          # 6 Woody branches      ->  2 Tree\n",
    "])\n",
    "\n",
    "FOR_Instance_CLASS_NAMES = [\n",
    "    'Ground',\n",
    "    'Low vegetation',\n",
    "    'Tree',\n",
    "    'Ignored']\n",
    "\n",
    "FOR_Instance_CLASS_COLORS = np.asarray([\n",
    "    [243, 214, 171],    # Ground\n",
    "    [204, 213, 174],    # Low vegetation\n",
    "    [ 70, 115,  66],    # Tree\n",
    "    [  0,   0,   0]     # Ignored\n",
    "])\n",
    "\n",
    "filepaths = [\n",
    "    \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/CULS/plot_3_annotated.las\",\n",
    "    \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/NIBIO/plot_10_annotated.las\",\n",
    "    \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/RMIT/train.las\",\n",
    "    \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/SCION/plot_35_annotated.las\",\n",
    "    \"/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/TUWIEN/train.las\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_FORinstance_plot(filepath, xyz=True, intensity=True, semantic=True, instance=True, remap=True, max_intensity=None):\n",
    "    \"\"\"\n",
    "    Read a FORinstance plot from a LAS file and return the data object.\n",
    "    \"\"\"\n",
    "    data = Data()\n",
    "    las = laspy.read(filepath)\n",
    "\n",
    "    if xyz:\n",
    "        pos = torch.stack([\n",
    "            torch.as_tensor(np.array(las[axis]))\n",
    "            for axis in [\"X\", \"Y\", \"Z\"]], dim=-1)\n",
    "        pos *= las.header.scale\n",
    "        pos_offset = pos[0]\n",
    "        data.pos = (pos - pos_offset).float()\n",
    "        data.pos_offset = pos_offset\n",
    "\n",
    "    intensity_remaped = True\n",
    "    if intensity:\n",
    "        data.intensity = torch.FloatTensor(\n",
    "            las['intensity'].astype('float32')\n",
    "        )\n",
    "        if intensity_remaped:\n",
    "            if max_intensity is None:\n",
    "                max_intensity = data.intensity.max()\n",
    "            data.intensity = data.intensity.clip(min=0, max=max_intensity) / max_intensity\n",
    "\n",
    "    if semantic:\n",
    "        y = torch.LongTensor(np.array(las['classification']))\n",
    "        data.y = torch.from_numpy(ID2TRAINID)[y] if remap else y\n",
    "\n",
    "    if instance:\n",
    "        idx = torch.arange(data.num_points)\n",
    "        obj = torch.LongTensor(np.array(las['treeID']))\n",
    "        \n",
    "        y = torch.LongTensor(np.array(las['classification']))\n",
    "        y = torch.from_numpy(ID2TRAINID)[y] if remap else y\n",
    "\n",
    "        if remap:\n",
    "            ground_mask = (obj == 0) & (y == 0)\n",
    "            low_veg_mask = (obj == 0) & (y == 1)\n",
    "            if low_veg_mask.any() or ground_mask.any():\n",
    "                ground_instance_label = obj.max().item() + 1\n",
    "                low_veg_instance_label = ground_instance_label + 1\n",
    "                obj[ground_mask] = ground_instance_label\n",
    "                obj[low_veg_mask] = low_veg_instance_label\n",
    "\n",
    "        obj = consecutive_cluster(obj)[0]\n",
    "        count = torch.ones_like(obj)\n",
    "\n",
    "        data.obj = InstanceData(idx, obj, count, y, dense=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transform(data, transform, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Helper function to apply a transform to the data and return the transformed data.\n",
    "    \"\"\"\n",
    "    return transform(*args, **kwargs)(data)\n",
    "\n",
    "def pre_transform(data, param_set):\n",
    "    \"\"\"\n",
    "    Pre-transform the data with the specified parameters and return the transformed data element as a nag.\n",
    "\n",
    "    The function applies a series of transformations to the input dataset and returns the transformed data.\n",
    "\n",
    "    Parameters:\n",
    "    data (object): A data object to be transformed and evaluated.\n",
    "    param_set (tuple): A tuple containing the parameters for the transformations in the following order:\n",
    "                          (voxel_size, k, r_max, threshold, scale, features, k_adj_graph, w, features_to_x, regularization,\n",
    "                            spatial_weight, cutoff, iterations, k_adjacency)\n",
    "\n",
    "    Returns:\n",
    "    object: nag, the transformed data element.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract parameters\n",
    "    (voxel_size, k, r_max, threshold, scale, features, k_adj_graph, w, features_to_x, \n",
    "         regularization, spatial_weight, cutoff, iterations, k_adjacency) = param_set\n",
    "\n",
    "    data = data.clone()\n",
    "    data = apply_transform(data, GridSampling3D, size=voxel_size, hist_key='y', hist_size=FOR_Instance_num_classes + 1)\n",
    "    data = apply_transform(data, KNN, k, r_max)\n",
    "    data = apply_transform(data, GroundElevation, threshold, scale)\n",
    "    data = apply_transform(data, PointFeatures, keys=features_to_x)\n",
    "    data = apply_transform(data, AdjacencyGraph, k_adj_graph, w)\n",
    "    data = apply_transform(data, AddKeysTo, keys=features_to_x, to='x', delete_after=False)\n",
    "    nag = apply_transform(data, CutPursuitPartition, regularization=regularization, \\\n",
    "                                   spatial_weight=spatial_weight, cutoff=cutoff, iterations=iterations, k_adjacency=k_adjacency)\n",
    "\n",
    "    return nag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_params_and_vis(data, param_set):\n",
    "    \"\"\"\n",
    "    Apply the parameters to the data and visualize the result.\n",
    "    \"\"\"\n",
    "    nag = pre_transform(data, param_set)\n",
    "    print('Tree iou: ', nag[1].semantic_segmentation_oracle(FOR_Instance_num_classes)['iou_per_class'][2].item())\n",
    "    print(nag[1].instance_segmentation_oracle(FOR_Instance_num_classes))\n",
    "    print(nag[1].panoptic_segmentation_oracle(FOR_Instance_num_classes))\n",
    "\n",
    "    nag.show(class_names=FOR_Instance_CLASS_NAMES, class_colors=FOR_Instance_CLASS_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "0: CULS\n",
    "1: NIBIO\n",
    "2: RMIT\n",
    "3: SCION\n",
    "4: TUWIEN\n",
    "\"\"\"\n",
    "data_CULS = read_FORinstance_plot(filepaths[0], instance=True)\n",
    "data_NIBIO = read_FORinstance_plot(filepaths[1], instance=True)\n",
    "data_RMIT = read_FORinstance_plot(filepaths[2], instance=True)\n",
    "data_SCION = read_FORinstance_plot(filepaths[3], instance=True)\n",
    "data_TUWIEN = read_FORinstance_plot(filepaths[4], instance=True)\n",
    "\n",
    "data_NIBIO_1 = read_FORinstance_plot('/home/valerio/git/superpoint_transformer_vschelbi/data/FORinstance/raw/NIBIO/plot_1_annotated.las', instance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0.1, 25, 3, 5, 20, ['intensity', 'linearity', 'planarity', 'scattering', 'verticality', 'elevation'], 5, 1, ['intensity', 'linearity', 'planarity', 'scattering', 'verticality', 'elevation'], [0.1, 0.2], [0.1, 0.01], [10, 30], 15, 5]\n",
    "\n",
    "#(voxel_size, k, r_max, threshold, scale, features, k_adj_graph, w, features_to_x, \n",
    "#         regularization, spatial_weight, cutoff, iterations, k_adjacency) = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_params_and_vis(data_CULS, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_params_and_vis(data_NIBIO, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_params_and_vis(data_NIBIO_1, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_params_and_vis(data_RMIT, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_params_and_vis(data_SCION, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_params_and_vis(data_TUWIEN, params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
