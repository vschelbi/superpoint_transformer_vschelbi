defaults:
  - default.yaml

# Partial NEST config specifically for the attention blocks
net:
  activation:
    _target_: torch.nn.LeakyReLU
    negative_slope: 0.01
  norm:
    _target_: src.nn.LayerNorm
    _partial_: True
  pre_norm: True
  no_sa: False
  no_ffn: True
  qk_dim: 4
  qkv_bias: True
  qk_scale: null
  scale_qk_by_neigh: True
  in_rpe_dim: ${eval:'${model._x_he_mlp} if ${model._x_he_mlp} else ${model._x_he_raw}'}
  k_rpe: True
  q_rpe: False
  c_rpe: False
  v_rpe: False
  stages_share_rpe: False
  blocks_share_rpe: False
  heads_share_rpe: False
