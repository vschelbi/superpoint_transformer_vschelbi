# @package model

_target_: src.models.panoptic.PanopticSegmentationModule

# Stuff class indices must be specified for instantiation.
# Concretely, stuff_classes is recovered from the datamodule config
stuff_classes: ${datamodule.stuff_classes}

# Minimum size for an instance to be taken into account in the instance
# segmentation metrics
min_instance_size: ${datamodule.min_instance_size}

# Make the point encoder slightly smaller than for the default SPT. This
# may slightly affect semantic segmentation results but allows fitting
# into 32G with the edge affinity head
_point_mlp: [32, 64, 64]  # point encoder layers

# Instance/panoptic partitioner module
partitioner:
  _target_: src.nn.instance.InstancePartitioner
  loss_type: 'l2_kl'
  regularization: 20
  x_weight: 0.01
  p_weight: 1
  cutoff: 1
  parallel: True
  iterations: 10
  trim: False
  discrepancy_epsilon: 1e-4
  temperature: 1
  dampening: 0

# Frequency at which the partition should be computed. If lower or equal
# to 0, the partition will only be computed at the last training epoch
partition_every_n_epochs: 50

# If True, the instance metrics will never be computed. If only panoptic
# metrics are of interest, this can save considerable training and
# evaluation time, as instance metrics computation is relatively slow
no_instance_metrics: True

# If True, the instance segmentation metrics will not be computed on the
# train set. This allows saving some computation and training time
no_instance_metrics_on_train_set: True

# Edge affinity loss
edge_affinity_criterion:
  _target_: src.loss.BCEWithLogitsLoss
  pos_weight: null

# Node offset loss
node_offset_criterion:
  _target_: src.loss.WeightedL2Loss

# Weights for combining the semantic segmentation loss with the node
# offset and edge affinity losses
edge_affinity_loss_lambda: 1
node_offset_loss_lambda: 1
