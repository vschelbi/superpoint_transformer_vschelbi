# @package model

_target_: src.models.panoptic.PanopticSegmentationModule

# Stuff class indices must be specified for instantiation.
# Concretely, stuff_classes is recovered from the datamodule config
stuff_classes: ${datamodule.stuff_classes}

# Minimum size for an instance to be taken into account in the instance
# segmentation metrics
min_instance_size: ${datamodule.min_instance_size}

# Make the point encoder slightly smaller than for the default SPT. This
# may slightly affect semantic segmentation results but allows fitting
# into 32G with the edge affinity head
_point_mlp: [32, 64, 64]  # point encoder layers

# Partial spt config specifically for the instance/panoptic partitioner
partitioner:
  _target_: src.nn.instance.InstancePartitioner
  regularization: 10
  x_weight: 0.1
  cutoff: 1
  parallel: True
  iterations: 10
  trim: False
  discrepancy_epsilon: 1e-4

# Frequency at which the partition should be computed. If lower or equal
# to 0, the partition will only be computed at the last training epoch
partition_every_n_epochs: 50

# If True, the instance segmentation metrics will not be computed on the
# train set. This allows saving some computation and training time
no_instance_on_train_set: True

# Edge affinity loss
edge_affinity_criterion:
  _target_: src.loss.BCEWithLogitsLoss
  pos_weight: null

# Node offset loss
node_offset_criterion:
  _target_: src.loss.WeightedL2Loss

# Weights for combining the semantic segmentation loss with the node
# offset and edge affinity losses
edge_affinity_loss_lambda: 1
node_offset_loss_lambda: 1
