# @package _global_

# to execute this experiment run:
# python train.py experiment=panoptic/kitti360_nano

defaults:
  - override /datamodule: panoptic/kitti360_nano.yaml
  - override /model: panoptic/nano-2.yaml
  - override /trainer: gpu.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

trainer:
  max_epochs: 200

model:
  optimizer:
    lr: 0.01
    weight_decay: 1e-4

  _down_dim: [ 32, 32, 32, 32 ]
  _up_dim: [ 32, 32, 32 ]
  _node_mlp_out: 32
  _h_edge_mlp_out: 32

  partitioner:
    loss_type: 'l2_kl'
    regularization: 20
    x_weight: 0.05
    p_weight: 1

  partition_every_n_epochs: 10

logger:
  wandb:
    project: "spt_kitti360"
    name: "NANO-32"

# metric based on which models will be selected
#optimized_metric: "val/pq"
#
#callbacks:
#  model_checkpoint:
#    every_n_epochs: ${eval:'max(${trainer.check_val_every_n_epoch}, ${model.partition_every_n_epochs})'}
#
#  early_stopping:
#    strict: False
